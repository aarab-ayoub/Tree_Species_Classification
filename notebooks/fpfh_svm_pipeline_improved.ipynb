{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base: /Users/ayoub/work/prjt/notebooks/..\n",
            "Data: /Users/ayoub/work/prjt/notebooks/../data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "sys.path.append(str(Path(\"..\").absolute()))\n",
        "from src.point_cloud_processor import load_point_cloud, extract_fpfh_features\n",
        "\n",
        "base_path = Path(\"..\")\n",
        "data_path = base_path / \"data\"\n",
        "print(\"Base:\", base_path.absolute())\n",
        "print(\"Data:\", data_path.absolute())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 557 | Test: 134 | Classes: ['Ash', 'Beech', 'Douglas Fir', 'Oak', 'Pine', 'Red Oak', 'Spruce']\n"
          ]
        }
      ],
      "source": [
        "# Dataset loading helpers (same logic as baseline)\n",
        "\n",
        "def load_from_folders(data_path: Path):\n",
        "\tX_train_paths, y_train, X_test_paths, y_test = [], [], [], []\n",
        "\ttrain_root = data_path.parent / \"train\"\n",
        "\ttest_root = data_path.parent / \"test\"\n",
        "\tif train_root.exists():\n",
        "\t\tfor species_dir in train_root.iterdir():\n",
        "\t\t\tif species_dir.is_dir():\n",
        "\t\t\t\tspecies = species_dir.name\n",
        "\t\t\t\tfor f in species_dir.iterdir():\n",
        "\t\t\t\t\tif f.is_file():\n",
        "\t\t\t\t\t\tX_train_paths.append(f)\n",
        "\t\t\t\t\t\ty_train.append(species)\n",
        "\tif test_root.exists():\n",
        "\t\tfor species_dir in test_root.iterdir():\n",
        "\t\t\tif species_dir.is_dir():\n",
        "\t\t\t\tspecies = species_dir.name\n",
        "\t\t\t\tfor f in species_dir.iterdir():\n",
        "\t\t\t\t\tif f.is_file():\n",
        "\t\t\t\t\t\tX_test_paths.append(f)\n",
        "\t\t\t\t\t\ty_test.append(species)\n",
        "\treturn X_train_paths, y_train, X_test_paths, y_test\n",
        "\n",
        "X_train_paths, y_train, X_test_paths, y_test = load_from_folders(data_path)\n",
        "print(f\"Train: {len(X_train_paths)} | Test: {len(X_test_paths)} | Classes: {sorted(set(y_train))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Voxel candidates: [0.1]\n"
          ]
        }
      ],
      "source": [
        "# Feature extraction with voxel_size as a parameter\n",
        "\n",
        "def extract_features(file_paths, voxel_size=0.2, feature_dim=33):\n",
        "\tfeatures = []\n",
        "\tfails = 0\n",
        "\tfor p in tqdm(file_paths, desc=f\"FPFH v={voxel_size}\"):\n",
        "\t\ttry:\n",
        "\t\t\tpcd = load_point_cloud(p)\n",
        "\t\t\tif pcd and len(np.asarray(pcd.points)) > 0:\n",
        "\t\t\t\tf = extract_fpfh_features(pcd, voxel_size=voxel_size)\n",
        "\t\t\t\tif f is not None and len(f) == feature_dim:\n",
        "\t\t\t\t\tfeatures.append(f)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tfeatures.append(np.zeros(feature_dim))\n",
        "\t\t\t\t\tfails += 1\n",
        "\t\t\telse:\n",
        "\t\t\t\tfeatures.append(np.zeros(feature_dim))\n",
        "\t\t\t\tfails += 1\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tfeatures.append(np.zeros(feature_dim))\n",
        "\t\t\tfails += 1\n",
        "\treturn np.array(features), fails\n",
        "\n",
        "# voxel_grid = [0.10, 0.15, 0.20, 0.30]\n",
        "voxel_grid = [0.10]\n",
        "print(\"Voxel candidates:\", voxel_grid)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Voxel size = 0.1\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "FPFH v=0.1: 100%|██████████| 557/557 [01:04<00:00,  8.68it/s]\n",
            "FPFH v=0.1: 100%|██████████| 134/134 [00:16<00:00,  8.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fails: train=0, test=0\n",
            "After SMOTE: (557, 33) -> (1029, 33)\n",
            "Grid done in 2.5s | best BA=0.9543 | params={'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "\n",
            "Best setting:\n",
            "0.1 {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "CV balanced acc: 0.9543\n",
            "Test accuracy: 0.8657\n"
          ]
        }
      ],
      "source": [
        "# Search over voxel_size: extract features, then SMOTE + scale, then SVM grid search\n",
        "best_summary = None\n",
        "summaries = []\n",
        "\n",
        "for vox in voxel_grid:\n",
        "\tprint(\"\\n\" + \"=\"*60)\n",
        "\tprint(f\"Voxel size = {vox}\")\n",
        "\tprint(\"=\"*60)\n",
        "\t\n",
        "\tXtr, fail_tr = extract_features(X_train_paths, voxel_size=vox)\n",
        "\tXte, fail_te = extract_features(X_test_paths, voxel_size=vox)\n",
        "\tprint(f\"Fails: train={fail_tr}, test={fail_te}\")\n",
        "\t\n",
        "\t# SMOTE to balance classes (on raw features)\n",
        "\tsmote = SMOTE(random_state=42)\n",
        "\tXtr_bal, ytr_bal = smote.fit_resample(Xtr, y_train)\n",
        "\tprint(f\"After SMOTE: {Xtr.shape} -> {Xtr_bal.shape}\")\n",
        "\t\n",
        "\t# Scale after balancing\n",
        "\tscaler = StandardScaler()\n",
        "\tXtr_scaled = scaler.fit_transform(Xtr_bal)\n",
        "\tXte_scaled = scaler.transform(Xte)\n",
        "\t\n",
        "\t# Grid search emphasizing minority recall\n",
        "\tparam_grid = {\n",
        "\t\t'C': [0.1, 1, 3, 10, 30, 100],\n",
        "\t\t'gamma': ['scale', 'auto', 0.03, 0.1, 0.3, 1],\n",
        "\t\t'class_weight': [None, 'balanced'],\n",
        "\t\t'kernel': ['rbf']\n",
        "\t}\n",
        "\tcv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\tgrid = GridSearchCV(SVC(random_state=42), param_grid, cv=cv, n_jobs=-1, verbose=0, scoring='balanced_accuracy')\n",
        "\tstart = time.time()\n",
        "\tgrid.fit(Xtr_scaled, ytr_bal)\n",
        "\tdur = time.time() - start\n",
        "\tprint(f\"Grid done in {dur:.1f}s | best BA={grid.best_score_:.4f} | params={grid.best_params_}\")\n",
        "\t\n",
        "\tbest_svm = grid.best_estimator_\n",
        "\ty_pred = best_svm.predict(Xte_scaled)\n",
        "\tacc = accuracy_score(y_test, y_pred)\n",
        "\treport = classification_report(y_test, y_pred, zero_division=0)\n",
        "\tcm = confusion_matrix(y_test, y_pred, labels=sorted(set(y_train)))\n",
        "\t\n",
        "\tsummary = {\n",
        "\t\t'voxel_size': vox,\n",
        "\t\t'fails_train': fail_tr,\n",
        "\t\t'fails_test': fail_te,\n",
        "\t\t'best_params': grid.best_params_,\n",
        "\t\t'balanced_accuracy_cv': grid.best_score_,\n",
        "\t\t'test_accuracy': acc,\n",
        "\t\t'classification_report': report,\n",
        "\t\t'confusion_matrix': cm\n",
        "\t}\n",
        "\tsummaries.append(summary)\n",
        "\t\n",
        "\t# Track best by balanced accuracy CV, tiebreak by test acc\n",
        "\tif best_summary is None:\n",
        "\t\tbest_summary = summary\n",
        "\telse:\n",
        "\t\tif summary['balanced_accuracy_cv'] > best_summary['balanced_accuracy_cv'] or \\\n",
        "\t\t  (summary['balanced_accuracy_cv'] == best_summary['balanced_accuracy_cv'] and summary['test_accuracy'] > best_summary['test_accuracy']):\n",
        "\t\t\tbest_summary = summary\n",
        "\n",
        "print(\"\\nBest setting:\")\n",
        "print(best_summary['voxel_size'], best_summary['best_params'])\n",
        "print(f\"CV balanced acc: {best_summary['balanced_accuracy_cv']:.4f}\")\n",
        "print(f\"Test accuracy: {best_summary['test_accuracy']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Best FPFH + SVM (with SMOTE) Configuration\n",
            "================================================================================\n",
            "Voxel size: 0.1\n",
            "Best params: {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "CV balanced accuracy: 0.9543\n",
            "Test accuracy: 0.8657\n",
            "\n",
            "Classification report (test):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Ash       0.56      0.71      0.62         7\n",
            "       Beech       0.93      0.88      0.90        32\n",
            " Douglas Fir       0.97      0.83      0.90        36\n",
            "         Oak       0.75      0.75      0.75         4\n",
            "        Pine       0.50      0.80      0.62         5\n",
            "     Red Oak       0.89      0.89      0.89        19\n",
            "      Spruce       0.88      0.94      0.91        31\n",
            "\n",
            "    accuracy                           0.87       134\n",
            "   macro avg       0.78      0.83      0.80       134\n",
            "weighted avg       0.88      0.87      0.87       134\n",
            "\n",
            "Confusion Matrix (test):\n",
            "\n",
            "             Ash  Beech  Douglas Fir  Oak  Pine  Red Oak  Spruce\n",
            "Ash            5      2            0    0     0        0       0\n",
            "Beech          3     28            0    0     1        0       0\n",
            "Douglas Fir    1      0           30    0     1        1       3\n",
            "Oak            0      0            0    3     0        1       0\n",
            "Pine           0      0            0    0     4        0       1\n",
            "Red Oak        0      0            1    1     0       17       0\n",
            "Spruce         0      0            0    0     2        0      29\n",
            "\n",
            "Note: We used SMOTE to balance classes and searched voxel_size values to stabilize FPFH.\n"
          ]
        }
      ],
      "source": [
        "# Pretty-print final report for the best configuration\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Best FPFH + SVM (with SMOTE) Configuration\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Voxel size: {best_summary['voxel_size']}\")\n",
        "print(f\"Best params: {best_summary['best_params']}\")\n",
        "print(f\"CV balanced accuracy: {best_summary['balanced_accuracy_cv']:.4f}\")\n",
        "print(f\"Test accuracy: {best_summary['test_accuracy']:.4f}\")\n",
        "print(\"\\nClassification report (test):\\n\")\n",
        "print(best_summary['classification_report'])\n",
        "\n",
        "classes = sorted(set(y_train))\n",
        "cm_df = pd.DataFrame(best_summary['confusion_matrix'], index=classes, columns=classes)\n",
        "print(\"Confusion Matrix (test):\\n\")\n",
        "print(cm_df)\n",
        "print(\"\\nNote: We used SMOTE to balance classes and searched voxel_size values to stabilize FPFH.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8656716417910447\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_score(y_test, best_svm.predict(Xte_scaled)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVC(C=10, random_state=42)\n"
          ]
        }
      ],
      "source": [
        "print(best_svm)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
