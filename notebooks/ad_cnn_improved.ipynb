{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "717b1b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      " Oak: 18 files\n",
      " Douglas Fir: 116 files\n",
      " cifar-10-batches-py: 0 files\n",
      " Spruce: 117 files\n",
      " Pine: 8 files\n",
      " Ash: 20 files\n",
      " Red Oak: 81 files\n",
      " Beech: 70 files\n",
      " Total: 430 files across 7 species\n",
      " Oak: 4 files\n",
      " Douglas Fir: 29 files\n",
      " cifar-10-batches-py: 0 files\n",
      " Spruce: 25 files\n",
      " Pine: 1 files\n",
      " Ash: 7 files\n",
      " Red Oak: 19 files\n",
      " Beech: 17 files\n",
      " Total: 102 files across 7 species\n",
      " Split: Train=344, Val=86, Test=102\n",
      "Class distribution in training: Counter({np.int64(6): 94, np.int64(2): 93, np.int64(5): 65, np.int64(1): 56, np.int64(0): 16, np.int64(3): 14, np.int64(4): 6})\n",
      "Class weights: {np.int64(1): np.float64(0.1336306209562122), np.int64(6): np.float64(0.10314212462587934), np.int64(2): np.float64(0.10369516947304253), np.int64(0): np.float64(0.25), np.int64(5): np.float64(0.12403473458920847), np.int64(3): np.float64(0.2672612419124244), np.int64(4): np.float64(0.4082482904638631)}\n",
      " Loaders ready. Sample shape: torch.Size([8, 6, 1, 224, 224]) (B, views, C, H, W)\n",
      " Model: 2,778,311 params\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 296\u001b[39m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_losses, val_losses, train_accs, val_accs, best_acc\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m train_losses, val_losses, train_accs, val_accs, best_val_acc = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[38;5;66;03m# Cell 6: Evaluate on Test Set with Best Model\u001b[39;00m\n\u001b[32m    299\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(model, loader):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 246\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs, patience)\u001b[39m\n\u001b[32m    243\u001b[39m loss.backward()\n\u001b[32m    244\u001b[39m optimizer.step()\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m loss_meter += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m _, pred = outputs.max(\u001b[32m1\u001b[39m)\n\u001b[32m    248\u001b[39m total += labels.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, RandomRotation, ColorJitter, RandomHorizontalFlip, RandomResizedCrop\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configuration - Optimized for better class balance\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 8 \n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 65\n",
    "PATIENCE = 15\n",
    "DEVICE = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "\n",
    "# Cell 2: Load Data\n",
    "def load_tree_data(data_path):\n",
    "    data_path = Path(data_path)\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "\n",
    "    if not data_path.exists():\n",
    "        raise FileNotFoundError(f\"{data_path} not found!\")\n",
    "\n",
    "    for species_dir in data_path.iterdir():\n",
    "        if species_dir.is_dir():\n",
    "            species_name = species_dir.name\n",
    "            files = list(species_dir.glob(\"*.npy\"))\n",
    "            print(f\" {species_name}: {len(files)} files\")\n",
    "            file_paths.extend(files)\n",
    "            labels.extend([species_name] * len(files))\n",
    "\n",
    "    print(f\" Total: {len(file_paths)} files across {len(set(labels))} species\")\n",
    "    return file_paths, labels\n",
    "\n",
    "# Load train and test separately\n",
    "train_data_path = Path(\"../data/multi_view_images/train\")\n",
    "test_data_path = Path(\"../data/multi_view_images/test\")\n",
    "\n",
    "train_file_paths, train_labels = load_tree_data(train_data_path)\n",
    "test_file_paths, test_labels = load_tree_data(test_data_path)\n",
    "\n",
    "if len(train_file_paths) == 0 or len(test_file_paths) == 0:\n",
    "    raise ValueError(\"No data found!\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels = train_labels + test_labels  # Fit on all for consistency\n",
    "label_encoder.fit(all_labels)\n",
    "train_encoded_labels = label_encoder.transform(train_labels)\n",
    "test_encoded_labels = label_encoder.transform(test_labels)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Split train into train/val (stratified)\n",
    "train_paths, val_paths, train_labels_enc, val_labels_enc = train_test_split(\n",
    "    train_file_paths, train_encoded_labels, test_size=0.2, random_state=42, stratify=train_encoded_labels\n",
    ")\n",
    "\n",
    "print(f\" Split: Train={len(train_paths)}, Val={len(val_paths)}, Test={len(test_file_paths)}\")\n",
    "\n",
    "\n",
    "# Cell 3: Dataset with WeightedRandomSampler\n",
    "class TreeMultiViewDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None, img_size=224):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        views_arr = np.load(self.file_paths[idx])\n",
    "        images = [Image.fromarray((view * 255).astype(np.uint8), mode='L') for view in views_arr]\n",
    "        \n",
    "        if self.transform:\n",
    "            images = [self.transform(img) for img in images]\n",
    "        \n",
    "        # Stack: (num_views, 1, H, W)\n",
    "        image_stack = torch.stack(images, dim=0)\n",
    "        label = self.labels[idx]\n",
    "        return image_stack, label\n",
    "    \n",
    "# Enhanced Transforms\n",
    "train_transform = Compose([\n",
    "    RandomResizedCrop(size=IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomRotation(15),\n",
    "    ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "test_transform = Compose([\n",
    "    Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_dataset = TreeMultiViewDataset(train_paths, train_labels_enc, train_transform)\n",
    "val_dataset = TreeMultiViewDataset(val_paths, val_labels_enc, test_transform)\n",
    "test_dataset = TreeMultiViewDataset(test_file_paths, test_encoded_labels, test_transform)\n",
    "\n",
    "# Added WeightedRandomSampler to handle class imbalance\n",
    "# Calculate class frequencies and sample weights\n",
    "class_counts = Counter(train_labels_enc)\n",
    "\n",
    "# class_weights = {cls: 1.0 / count for cls, count in class_counts.items()}\n",
    "class_weights = {cls: 1.0 / np.sqrt(count) for cls, count in class_counts.items()}\n",
    "\n",
    "sample_weights = [class_weights[label] for label in train_labels_enc]\n",
    "\n",
    "print(f\"Class distribution in training: {class_counts}\")\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# Create WeightedRandomSampler - with smaller batch size for better rare class representation\n",
    "weighted_sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# Loaders - Note: shuffle=False when using sampler\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=weighted_sampler, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# Check sample shape\n",
    "sample_shape = next(iter(train_loader))[0].shape\n",
    "print(f\" Loaders ready. Sample shape: {sample_shape} (B, views, C, H, W)\")\n",
    "\n",
    "# Cell 4: Model with Max Pooling Aggregation\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        return self.relu(out)\n",
    "\n",
    "class MultiViewCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, 2, 1),\n",
    "            BasicBlock(64, 64),\n",
    "            BasicBlock(64, 64),\n",
    "            BasicBlock(64, 128, 2),\n",
    "            BasicBlock(128, 128),\n",
    "            BasicBlock(128, 256, 2),\n",
    "            BasicBlock(256, 256),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.7)  # Added dropout for regularization\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: (B, views, 1, H, W)\n",
    "        if x.dim() == 5:\n",
    "            b, views, c, h, w = x.shape\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected input tensor shape {x.shape}\")\n",
    "\n",
    "        x = x.view(-1, c, h, w)  # (B*views, 1, H, W)\n",
    "        x = self.features(x)     # (B*views, 256, 1, 1)\n",
    "        x = x.view(b, views, -1) # (B, views, 256)\n",
    "        \n",
    "        # Changed from mean to max pooling over views - captures most prominent features\n",
    "        x, _ = torch.max(x, dim=1)  # (B, 256) - Use max pooling over the views\n",
    "        \n",
    "        x = self.dropout(x)      # Dropout before classifier\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Model\n",
    "model = MultiViewCNN(num_classes).to(DEVICE)\n",
    "\n",
    "# Weighted loss for imbalance\n",
    "class_weights_tensor = [1.0 / Counter(train_labels_enc)[i] for i in range(num_classes)]\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights_tensor).to(DEVICE))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "\n",
    "# Changed to CosineAnnealingLR scheduler for better convergence\n",
    "# Using warm restarts to help with smaller batch training\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "print(f\" Model: {sum(p.numel() for p in model.parameters()):,} params\")\n",
    "\n",
    "\n",
    "# Cell 5: Training Loop with Enhanced Scheduler\n",
    "def train_model(model, train_loader, val_loader, epochs, patience):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    best_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        loss_meter = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for views, labels in train_loader:\n",
    "            views, labels = views.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(views)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_meter += loss.item()\n",
    "            _, pred = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "\n",
    "        train_loss = loss_meter / len(train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for views, labels in val_loader:\n",
    "                views, labels = views.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(views)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, pred = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += pred.eq(labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100. * val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        # CosineAnnealingWarmRestarts scheduler step at the end of each epoch\n",
    "        scheduler.step()\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"Epoch {epoch+1:2d}/{epochs} | Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}% | LR: {current_lr:.6f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            patience_counter = 0\n",
    "            print(f\"  New best val acc: {best_acc:.2f}% - Model saved ðŸš©\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    print(f\"Training done in {time.time() - start_time:.2f}s\")\n",
    "    return train_losses, val_losses, train_accs, val_accs, best_acc\n",
    "\n",
    "# Train\n",
    "train_losses, val_losses, train_accs, val_accs, best_val_acc = train_model(model, train_loader, val_loader, NUM_EPOCHS, PATIENCE)\n",
    "\n",
    "# Cell 6: Evaluate on Test Set with Best Model\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for views, labels in loader:\n",
    "            views, labels = views.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(views)\n",
    "            _, pred = outputs.max(1)\n",
    "            preds.append(pred.cpu())\n",
    "            targets.append(labels.cpu())\n",
    "    return torch.cat(preds).numpy(), torch.cat(targets).numpy()\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "print(\"Best model loaded for evaluation\")\n",
    "\n",
    "y_pred, y_true = evaluate(model, test_loader)\n",
    "test_acc = accuracy_score(y_true, y_pred) * 100\n",
    "\n",
    "print(f\"\\n Final Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"Best Val Accuracy: {best_val_acc:.2f}%\")\n",
    "\n",
    "# Report\n",
    "names = label_encoder.classes_\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=names))\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses, label=\"Train Loss\", lw=2)\n",
    "plt.plot(val_losses, label=\"Val Loss\", lw=2)\n",
    "plt.legend(); plt.title(\"Loss\"); plt.grid()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(train_accs, label=\"Train Acc\", lw=2)\n",
    "plt.plot(val_accs, label=\"Val Acc\", lw=2)\n",
    "plt.legend(); plt.title(\"Accuracy\"); plt.grid()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "cm = confusion_matrix(y_true, y_pred, labels=range(len(names)))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=names, yticklabels=names)\n",
    "plt.title(\"Confusion Matrix\"); plt.xticks(rotation=45); plt.yticks(rotation=45)\n",
    "plt.tight_layout(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
